{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bff55003-d1f7-4aa2-bb30-365027c5b129",
   "metadata": {},
   "source": [
    "## Trader Joes Scraper Example ##\n",
    "\n",
    "The following notebook is to guide the user through the web scraping process for extracting prices and recipes from the grocery store, Trader Joe's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5673b127-97cc-4997-8a0d-ea3725a35055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc68bf3c-1701-41bc-9853-bf49b74155e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n",
      "<HTML><HEAD>\n",
      "<TITLE>Access Denied</TITLE>\n",
      "</HEAD><BODY>\n",
      "<H1>Access Denied</H1>\n",
      " \n",
      "You don't have permission to access \"http&#58;&#47;&#47;www&#46;traderjoes&#46;com&#47;home&#47;products&#47;category&#47;produce\" on this server.<P>\n",
      "Reference&#32;&#35;18&#46;8609c617&#46;1760809290&#46;35d68d6f\n",
      "<P>https&#58;&#47;&#47;errors&#46;edgesuite&#46;net&#47;18&#46;8609c617&#46;1760809290&#46;35d68d6f</P>\n",
      "</BODY>\n",
      "</HTML>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.traderjoes.com/home/products/category/produce\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check that it worked (HTTP 200 = OK)\n",
    "print(response.status_code)\n",
    "\n",
    "# Display the first few hundred characters of the HTML\n",
    "print(response.text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13261b3-62f4-4b8f-a461-937c762fd96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/122.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.traderjoes.com/\"\n",
    "}\n",
    "\n",
    "url = \"https://www.traderjoes.com/home/products/category/produce\"\n",
    "response = requests.get(url, headers=headers)\n",
    "print(response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d44f49b-9dce-463e-be02-0268e0c7b1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html lang=\"en\"><head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <title>Products | Trader Joe's</title><script src=\"https://static.klaviyo.com/onsite/js/klaviyo.js?company_id=YyBHyr\" async=\"\" defer=\"\"></script>\n",
      "    \n",
      "    \n",
      "    <meta name=\"template\" content=\"product-category-template\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
      "    \n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "<script type=\"text/javascript\" async=\"\" src=\"https://www.google-analytics.com/analytics.js\"></script><script type=\"text/javascript\" async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=G-2HMPBJHQ41&amp;cx=c&amp;gtm=4e5af1h1\"></script><script async=\"\" src=\"https://www.googletagmanager.com/gtm.js?id=GTM-PK37XV6\"></script><script defer=\"defer\" type=\"text/javascript\" src=\"/.rum/@adobe/helix-rum-js@%5E2/dist/rum-standalone.js\"></script>\n",
      "<link rel=\"canonical\" href=\"/home/products/category.html\">\n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "    \n",
      "    \n",
      "<link rel=\"stylesheet\" href=\"/etc.clientlibs/trjo/clientlibs/clientlib-base.lc-af48c5ed2ea1d900b5b89d68fe8fab26-lc\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# Chrome options\n",
    "options = Options()\n",
    "#options.add_argument(\"--headless\")  # runs Chrome without opening a window\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Navigate to the page\n",
    "url = \"https://www.traderjoes.com/home/products/category/produce\"\n",
    "driver.get(url)\n",
    "\n",
    "# Allow page to fully load\n",
    "time.sleep(3)\n",
    "\n",
    "# Get the HTML\n",
    "html = driver.page_source\n",
    "print(html[:1000])  # print first 1000 chars to confirm it loaded\n",
    "\n",
    "# Always quit when done\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02f6f27-4182-4122-9e19-56f5fb87eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 403 <HTML><HEAD>\n",
      "<TITLE>Access Denied</TITLE>\n",
      "</HEAD><BODY>\n",
      "<H1>Access Denied</H1>\n",
      " \n",
      "You don't have permission to access \"http&#58;&#47;&#47;www&#46;traderjoes&#46;com&#47;graphql\" on this server.<P>\n",
      "Reference&#32;&#35;18&#46;8609c617&#46;1760809777&#46;35fd0762\n",
      "<P>https&#58;&#47;&#47;errors&#46;edgesuite&#46;net&#47;18&#46;8609c617&#46;1760809777&#46;35fd0762</P>\n",
      "</BODY>\n",
      "</HTML>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://www.traderjoes.com/graphql\"\n",
    "\n",
    "query = \"\"\"\n",
    "query SearchProducts($pageSize: Int, $currentPage: Int, $storeCode: String, $published: String = \"1\") {\n",
    "  products(\n",
    "    filter: {store_code: {eq: $storeCode}, published: {eq: $published}}\n",
    "    pageSize: $pageSize\n",
    "    currentPage: $currentPage\n",
    "  ) {\n",
    "    items {\n",
    "      sku\n",
    "      item_title\n",
    "      item_description\n",
    "      retail_price\n",
    "      country_of_origin\n",
    "      availability\n",
    "      updated_at\n",
    "    }\n",
    "    total_count\n",
    "    page_info {\n",
    "      current_page\n",
    "      total_pages\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "variables = {\n",
    "    \"pageSize\": 50,\n",
    "    \"currentPage\": 1,\n",
    "    \"storeCode\": \"701\"\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"User-Agent\": \"Mozilla/5.0\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json={\"query\": query, \"variables\": variables})\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(json.dumps(data, indent=2))\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "888b89af-7971-4288-817a-a3dc18c15dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Title: Organic Milk A2/A2\n",
      "Price: $5.99\n",
      "{'CALORIES PER SERVING': '150',\n",
      " 'Calcium': {'%dv': '25%', 'amount': '300 mg'},\n",
      " 'Cholesterol': {'%dv': '10%', 'amount': '30 mg'},\n",
      " 'Dietary Fiber': {'%dv': '0%', 'amount': '0 g'},\n",
      " 'Includes': {'%dv': '0%', 'amount': '0 g Added Sugars'},\n",
      " 'Iron': {'%dv': '0%', 'amount': '0.0 mg'},\n",
      " 'Potassium': {'%dv': '8%', 'amount': '370 mg'},\n",
      " 'Protein': {'%dv': '', 'amount': '8 g'},\n",
      " 'SERVES 8': None,\n",
      " 'SERVING SIZE': '1 cup(240ml)',\n",
      " 'Saturated Fat': {'%dv': '23%', 'amount': '4.5 g'},\n",
      " 'Sodium': {'%dv': '4%', 'amount': '95 mg'},\n",
      " 'Total Carbohydrate': {'%dv': '4%', 'amount': '11 g'},\n",
      " 'Total Fat': {'%dv': '12%', 'amount': '9 g'},\n",
      " 'Total Sugars': {'%dv': '', 'amount': '12 g'},\n",
      " 'Trans Fat': {'%dv': '', 'amount': '0 g'},\n",
      " 'Vitamin A': {'%dv': '2%', 'amount': '20 mcg'},\n",
      " 'Vitamin D': {'%dv': '10%', 'amount': '2.4 mcg'}}\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "driver.get(\"https://www.traderjoes.com/home/products/pdp/organic-milk-a2a2-080971\")\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "time.sleep(5)\n",
    "# Extract product details\n",
    "\n",
    "try:\n",
    "    product_title = driver.find_element(By.CSS_SELECTOR, \"h1.ProductDetails_main__title__14Cnm\").text\n",
    "    product_price = driver.find_element(By.CSS_SELECTOR, \"span.ProductPrice_productPrice__price__3-50j\").text\n",
    "\n",
    "    print(\"Product Title:\", product_title)\n",
    "    print(\"Price:\", product_price)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error extracting product details:\", e)\n",
    "\n",
    "nutrition_data = {}\n",
    "\n",
    "try:\n",
    "    # 1. Find the nutrition container\n",
    "    container = driver.find_element(By.CSS_SELECTOR, \"div.NutritionFacts_nutritionFacts__1Nvz0\")\n",
    "\n",
    "    # 2. Extract characteristics (serving size, calories, etc.)\n",
    "    characteristics = container.find_elements(By.CSS_SELECTOR, \"div.Item_characteristics__item__2TgL-\")\n",
    "    for item in characteristics:\n",
    "        title_elem = item.find_element(By.CSS_SELECTOR, \"div.Item_characteristics__title__7nfa8\")\n",
    "        try:\n",
    "            text_elem = item.find_element(By.CSS_SELECTOR, \"div.Item_characteristics__text__dcfEC\")\n",
    "            nutrition_data[title_elem.text] = text_elem.text\n",
    "        except:\n",
    "            nutrition_data[title_elem.text] = None\n",
    "\n",
    "    # 3. Extract table data\n",
    "    rows = container.find_elements(By.CSS_SELECTOR, \"table.Item_table__2PMbE tbody tr\")\n",
    "    for row in rows:\n",
    "        cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        if len(cells) == 3:\n",
    "            nutrient = cells[0].text\n",
    "            amount = cells[1].text\n",
    "            dv = cells[2].text\n",
    "            nutrition_data[nutrient] = {\"amount\": amount, \"%dv\": dv}\n",
    "\n",
    "    # Print results\n",
    "    from pprint import pprint\n",
    "    pprint(nutrition_data)\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "258ec5a0-407e-4fbc-9a02-80ebcc2c10a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "✅ No more pages to scrape.\n",
      "                          name  price    unit  \\\n",
      "0    Organic Crimini Mushrooms  $2.69   /8 Oz   \n",
      "1       Organic Sweet Potatoes  $4.99   /3 Lb   \n",
      "2                 Fresh Fennel  $2.49  /20 Oz   \n",
      "3                Trimmed Leeks  $2.49   /6 Oz   \n",
      "4  Steamed & Peeled Baby Beets  $2.29   /8 Oz   \n",
      "\n",
      "                                                 url  page  \n",
      "0  https://www.traderjoes.com/home/products/pdp/o...     1  \n",
      "1  https://www.traderjoes.com/home/products/pdp/o...     1  \n",
      "2  https://www.traderjoes.com/home/products/pdp/f...     1  \n",
      "3  https://www.traderjoes.com/home/products/pdp/t...     1  \n",
      "4  https://www.traderjoes.com/home/products/pdp/s...     1  \n",
      "✅ Saved traderjoes_fresh-fruits-veggies_products.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "def scrape_category(url):\n",
    "    chrome_options = Options()\n",
    "    #chrome_options.add_argument(\"--headless=new\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    driver.get(url)\n",
    "\n",
    "    all_products = []\n",
    "    page = 1\n",
    "    time.sleep(3)\n",
    "    while True:\n",
    "        print(f\"Scraping page {page}...\")\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"section.ProductCard_card__4WAOg\"))\n",
    "        )\n",
    "    \n",
    "        # --- scrape cards (same as before) ---\n",
    "        cards = driver.find_elements(By.CSS_SELECTOR, \"section.ProductCard_card__4WAOg\")\n",
    "        for card in cards:\n",
    "            try:\n",
    "                name_elem = card.find_element(By.CSS_SELECTOR, \"h2 a\")\n",
    "                name = name_elem.text.strip()\n",
    "                link = name_elem.get_attribute(\"href\")\n",
    "            except:\n",
    "                name = None\n",
    "                link = None\n",
    "    \n",
    "            try:\n",
    "                price = card.find_element(By.CSS_SELECTOR, \"span.ProductPrice_productPrice__price__3-50j\").text.strip()\n",
    "            except:\n",
    "                price = None\n",
    "    \n",
    "            try:\n",
    "                unit = card.find_element(By.CSS_SELECTOR, \"span.ProductPrice_productPrice__unit__2jvkA\").text.strip()\n",
    "            except:\n",
    "                unit = None\n",
    "    \n",
    "            all_products.append({\n",
    "                \"name\": name, \"price\": price, \"unit\": unit, \"url\": link, \"page\": page\n",
    "            })\n",
    "    \n",
    "        # --- pagination handling ---\n",
    "\n",
    "        try:\n",
    "            current_page_elem = driver.find_element(\n",
    "                By.CSS_SELECTOR, \"li.PaginationItem_paginationItem_selected__3BZC-\"\n",
    "            )\n",
    "            current_page_text = current_page_elem.text.strip()\n",
    "        \n",
    "            # Try extracting digits from text or aria-label\n",
    "            match = re.search(r'\\d+', current_page_text)\n",
    "            if not match:\n",
    "                aria_label = current_page_elem.get_attribute(\"aria-label\") or \"\"\n",
    "                match = re.search(r'\\d+', aria_label)\n",
    "        \n",
    "            if match:\n",
    "                current_page = match.group()\n",
    "            else:\n",
    "                print(\"⚠️ Could not determine current page number, stopping.\")\n",
    "                break\n",
    "        \n",
    "            pagination_items = driver.find_elements(\n",
    "                By.CSS_SELECTOR, \"li.PaginationItem_paginationItem__2f87h\"\n",
    "            )\n",
    "        \n",
    "            next_item = None\n",
    "            for item in pagination_items:\n",
    "                label = item.text.strip() or (item.get_attribute(\"aria-label\") or \"\")\n",
    "                m = re.search(r'\\d+', label)\n",
    "                if m and m.group() == str(int(current_page) + 1):\n",
    "                    next_item = item\n",
    "                    break\n",
    "        \n",
    "            if not next_item:\n",
    "                print(\"✅ No more pages to scrape.\")\n",
    "                break\n",
    "        \n",
    "            driver.execute_script(\"arguments[0].click();\", next_item)\n",
    "        \n",
    "            # Wait for the selected page to update visually\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.text_to_be_present_in_element(\n",
    "                    (By.CSS_SELECTOR, \"li.PaginationItem_paginationItem_selected__3BZC-\"),\n",
    "                    str(int(current_page) + 1)\n",
    "                )\n",
    "            )\n",
    "        \n",
    "            page += 1\n",
    "            time.sleep(1)\n",
    "        \n",
    "        except (TimeoutException, StaleElementReferenceException):\n",
    "            print(\"⚠️ Pagination ended or element went stale.\")\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "    return pd.DataFrame(all_products)\n",
    "\n",
    "\n",
    "# ---- Run it ----\n",
    "#url = \"https://www.traderjoes.com/home/products/category/meat-seafood-plant-based-122\"\n",
    "url = \"https://www.traderjoes.com/home/products/category/fresh-fruits-veggies-113\"\n",
    "df = scrape_category(url)\n",
    "\n",
    "# Preview results\n",
    "print(df.head())\n",
    "\n",
    "# Save locally\n",
    "df.to_csv(\"traderjoes_fresh-fruits-veggies_products.csv\", index=False)\n",
    "print(\"✅ Saved traderjoes_fresh-fruits-veggies_products.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a465ba59-cdd3-4860-9b44-c33eb2f37023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Bakery - page 1...\n",
      "Scraping Bakery - page 2...\n",
      "Scraping Bakery - page 3...\n",
      "Scraping Bakery - page 4...\n",
      "Scraping Bakery - page 5...\n",
      "Scraping Bakery - page 6...\n",
      "✅ Finished Bakery.\n",
      "Scraping Cheese - page 1...\n",
      "Scraping Cheese - page 2...\n",
      "Scraping Cheese - page 3...\n",
      "Scraping Cheese - page 4...\n",
      "Scraping Cheese - page 5...\n",
      "✅ Finished Cheese.\n",
      "Scraping Dairy & Eggs - page 1...\n",
      "Scraping Dairy & Eggs - page 2...\n",
      "Scraping Dairy & Eggs - page 3...\n",
      "✅ Finished Dairy & Eggs.\n",
      "Scraping Dips, Sauces & Dressings - page 1...\n",
      "Scraping Dips, Sauces & Dressings - page 2...\n",
      "Scraping Dips, Sauces & Dressings - page 3...\n",
      "Scraping Dips, Sauces & Dressings - page 4...\n",
      "Scraping Dips, Sauces & Dressings - page 5...\n",
      "Scraping Dips, Sauces & Dressings - page 6...\n",
      "Scraping Dips, Sauces & Dressings - page 7...\n",
      "✅ Finished Dips, Sauces & Dressings.\n",
      "Scraping Fresh Prepared Foods - page 1...\n",
      "Scraping Fresh Prepared Foods - page 2...\n",
      "Scraping Fresh Prepared Foods - page 3...\n",
      "Scraping Fresh Prepared Foods - page 4...\n",
      "Scraping Fresh Prepared Foods - page 5...\n",
      "Scraping Fresh Prepared Foods - page 6...\n",
      "Scraping Fresh Prepared Foods - page 7...\n",
      "✅ Finished Fresh Prepared Foods.\n",
      "Scraping From the Freezer - page 1...\n",
      "Scraping From the Freezer - page 2...\n",
      "Scraping From the Freezer - page 3...\n",
      "Scraping From the Freezer - page 4...\n",
      "Scraping From the Freezer - page 5...\n",
      "Scraping From the Freezer - page 6...\n",
      "Scraping From the Freezer - page 7...\n",
      "Scraping From the Freezer - page 8...\n",
      "Scraping From the Freezer - page 9...\n",
      "Scraping From the Freezer - page 10...\n",
      "Scraping From the Freezer - page 11...\n",
      "Scraping From the Freezer - page 12...\n",
      "Scraping From the Freezer - page 13...\n",
      "Scraping From the Freezer - page 14...\n",
      "Scraping From the Freezer - page 15...\n",
      "✅ Finished From the Freezer.\n",
      "Scraping Fresh Fruits & Veggies - page 1...\n",
      "Scraping Fresh Fruits & Veggies - page 2...\n",
      "Scraping Fresh Fruits & Veggies - page 3...\n",
      "Scraping Fresh Fruits & Veggies - page 4...\n",
      "Scraping Fresh Fruits & Veggies - page 5...\n",
      "Scraping Fresh Fruits & Veggies - page 6...\n",
      "Scraping Fresh Fruits & Veggies - page 7...\n",
      "✅ Finished Fresh Fruits & Veggies.\n",
      "Scraping Meat, Seafood & Plant-Based - page 1...\n",
      "Scraping Meat, Seafood & Plant-Based - page 2...\n",
      "Scraping Meat, Seafood & Plant-Based - page 3...\n",
      "Scraping Meat, Seafood & Plant-Based - page 4...\n",
      "Scraping Meat, Seafood & Plant-Based - page 5...\n",
      "Scraping Meat, Seafood & Plant-Based - page 6...\n",
      "Scraping Meat, Seafood & Plant-Based - page 7...\n",
      "✅ Finished Meat, Seafood & Plant-Based.\n",
      "Scraping For the Pantry - page 1...\n",
      "Scraping For the Pantry - page 2...\n",
      "Scraping For the Pantry - page 3...\n",
      "Scraping For the Pantry - page 4...\n",
      "Scraping For the Pantry - page 5...\n",
      "Scraping For the Pantry - page 6...\n",
      "Scraping For the Pantry - page 7...\n",
      "Scraping For the Pantry - page 8...\n",
      "Scraping For the Pantry - page 9...\n",
      "Scraping For the Pantry - page 10...\n",
      "Scraping For the Pantry - page 11...\n",
      "Scraping For the Pantry - page 12...\n",
      "Scraping For the Pantry - page 13...\n",
      "Scraping For the Pantry - page 14...\n",
      "Scraping For the Pantry - page 15...\n",
      "✅ Finished For the Pantry.\n",
      "Scraping Snacks & Sweets - page 1...\n",
      "Scraping Snacks & Sweets - page 2...\n",
      "Scraping Snacks & Sweets - page 3...\n",
      "Scraping Snacks & Sweets - page 4...\n",
      "Scraping Snacks & Sweets - page 5...\n",
      "Scraping Snacks & Sweets - page 6...\n",
      "Scraping Snacks & Sweets - page 7...\n",
      "Scraping Snacks & Sweets - page 8...\n",
      "Scraping Snacks & Sweets - page 9...\n",
      "Scraping Snacks & Sweets - page 10...\n",
      "Scraping Snacks & Sweets - page 11...\n",
      "Scraping Snacks & Sweets - page 12...\n",
      "Scraping Snacks & Sweets - page 13...\n",
      "Scraping Snacks & Sweets - page 14...\n",
      "Scraping Snacks & Sweets - page 15...\n",
      "Scraping Snacks & Sweets - page 16...\n",
      "✅ Finished Snacks & Sweets.\n",
      "\n",
      " Finished scraping to 'trader_joes_products.csv'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time, re\n",
    "\n",
    "# ---- Selenium setup ----\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# ---- Helper function to scrape a single category ----\n",
    "def scrape_category(url, category_name):\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    products = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        print(f\"Scraping {category_name} - page {page}...\")\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"section.ProductCard_card__4WAOg\"))\n",
    "        )\n",
    "        cards = driver.find_elements(By.CSS_SELECTOR, \"section.ProductCard_card__4WAOg\")\n",
    "\n",
    "        for card in cards:\n",
    "            try:\n",
    "                link_elem = card.find_element(By.CSS_SELECTOR, \"h2 a\")\n",
    "                name = link_elem.text.strip()\n",
    "                link = link_elem.get_attribute(\"href\")\n",
    "            except:\n",
    "                name = None\n",
    "                link = None\n",
    "\n",
    "            try:\n",
    "                price = card.find_element(By.CSS_SELECTOR, \"span.ProductPrice_productPrice__price__3-50j\").text.strip()\n",
    "            except:\n",
    "                price = None\n",
    "\n",
    "            try:\n",
    "                unit = card.find_element(By.CSS_SELECTOR, \"span.ProductPrice_productPrice__unit__2jvkA\").text.strip()\n",
    "            except:\n",
    "                unit = None\n",
    "\n",
    "            products.append({\n",
    "                \"category\": category_name,\n",
    "                \"product_name\": name,\n",
    "                \"price\": price,\n",
    "                \"unit\": unit, \n",
    "                \"url\": link\n",
    "            })\n",
    "\n",
    "        # ---- Pagination ----\n",
    "        try:\n",
    "            current_page_elem = driver.find_element(By.CSS_SELECTOR, \"li.PaginationItem_paginationItem_selected__3BZC-\")\n",
    "            current_page_text = current_page_elem.text.strip()\n",
    "            match = re.search(r'\\d+', current_page_text)\n",
    "\n",
    "            if not match:\n",
    "                aria_label = current_page_elem.get_attribute(\"aria-label\") or \"\"\n",
    "                match = re.search(r'\\d+', aria_label)\n",
    "\n",
    "            if not match:\n",
    "                print(\"⚠️ Can't determine current page. Stopping pagination.\")\n",
    "                break\n",
    "\n",
    "            current_page = int(match.group())\n",
    "\n",
    "            pagination_items = driver.find_elements(By.CSS_SELECTOR, \"li.PaginationItem_paginationItem__2f87h\")\n",
    "            next_item = None\n",
    "            for item in pagination_items:\n",
    "                label = item.text.strip() or (item.get_attribute(\"aria-label\") or \"\")\n",
    "                m = re.search(r'\\d+', label)\n",
    "                if m and int(m.group()) == current_page + 1:\n",
    "                    next_item = item\n",
    "                    break\n",
    "\n",
    "            if not next_item:\n",
    "                print(f\"✅ Finished {category_name}.\")\n",
    "                break\n",
    "\n",
    "            driver.execute_script(\"arguments[0].click();\", next_item)\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.text_to_be_present_in_element(\n",
    "                    (By.CSS_SELECTOR, \"li.PaginationItem_paginationItem_selected__3BZC-\"),\n",
    "                    str(current_page + 1)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            page += 1\n",
    "            time.sleep(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Pagination stopped for {category_name}: {e}\")\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(products)\n",
    "\n",
    "\n",
    "# ---- Categories to scrape ----\n",
    "categories = {\n",
    "    \"Bakery\": \"https://www.traderjoes.com/home/products/category/bakery-11\",\n",
    "    \"Cheese\": \"https://www.traderjoes.com/home/products/category/cheese-29\",\n",
    "    \"Dairy & Eggs\": \"https://www.traderjoes.com/home/products/category/dairy-eggs-44\",\n",
    "    \"Dips, Sauces & Dressings\": \"https://www.traderjoes.com/home/products/category/dips-sauces-dressings-59\",\n",
    "    \"Fresh Prepared Foods\": \"https://www.traderjoes.com/home/products/category/fresh-prepared-foods-80\",\n",
    "    \"From the Freezer\": \"https://www.traderjoes.com/home/products/category/from-the-freezer-95\",\n",
    "    \"Fresh Fruits & Veggies\": \"https://www.traderjoes.com/home/products/category/fresh-fruits-veggies-113\",\n",
    "    \"Meat, Seafood & Plant-Based\": \"https://www.traderjoes.com/home/products/category/meat-seafood-plant-based-122\",\n",
    "    \"For the Pantry\": \"https://www.traderjoes.com/home/products/category/for-the-pantry-137\",\n",
    "    \"Snacks & Sweets\": \"https://www.traderjoes.com/home/products/category/snacks-sweets-167\"\n",
    "}\n",
    "\n",
    "# ---- Run through all categories ----\n",
    "all_data = []\n",
    "for category, link in categories.items():\n",
    "    df = scrape_category(link, category)\n",
    "    all_data.append(df)\n",
    "\n",
    "# ---- Combine & save ----\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "final_df.to_csv(\"trader_joes_products.csv\", index=False)\n",
    "\n",
    "print(\"\\n Finished scraping to 'trader_joes_products.csv'\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec9f4fe-d411-4668-9684-7914028ee9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
