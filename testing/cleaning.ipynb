{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-29T16:34:31.108482Z",
     "start_time": "2025-10-29T16:34:30.531966Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "from __future__ import annotations\n",
    "\n",
    "recipes = pd.read_csv(\"../web_scraper/trader_joes_recipes.csv\")\n",
    "products = pd.read_csv(\"../web_scraper/trader_joes_products.csv\")\n",
    "fruit_veg = pd.read_csv(\"../web_scraper/traderjoes_fresh-fruits-veggies_products.csv\")\n",
    "meat = pd.read_csv(\"../web_scraper/traderjoes_meat_products.csv\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:34:31.266922Z",
     "start_time": "2025-10-29T16:34:31.120799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "recipes[\"ingredients\"] = recipes[\"ingredients\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "def split_ingredient(text):\n",
    "    \"\"\"\n",
    "    Split strings like '4 tablespoons TJ’s Salted Butter' into:\n",
    "    quantity = '4 tablespoons', ingredient = \"TJ’s Salted Butter\"\n",
    "    \"\"\"\n",
    "    # Simple regex to separate numbers/units from ingredient name\n",
    "    match = re.match(r\"([\\d¼½¾⅓⅔⅛⅜⅝⅞\\s\\-–/a-zA-Z]+)\\s+(.*)\", text)\n",
    "    if match:\n",
    "        qty = match.group(1).strip()\n",
    "        name = match.group(2).strip()\n",
    "    else:\n",
    "        qty, name = None, text.strip()\n",
    "    return pd.Series([qty, name])\n",
    "\n",
    "recipes_exploded = recipes.explode(\"ingredients\", ignore_index=True)\n",
    "recipes_exploded[[\"quantity_text\", \"ingredient_name\"]] = recipes_exploded[\"ingredients\"].apply(split_ingredient)\n",
    "\n",
    "cookbook_df = recipes_exploded[[\"title\", \"category\", \"ingredient_name\", \"quantity_text\"]]\n",
    "possible_ingredients = cookbook_df['ingredient_name'].unique()\n",
    "possible_ingredients_df = pd.DataFrame(possible_ingredients, columns=[\"Ingredient\"])\n",
    "possible_ingredients_df"
   ],
   "id": "e44c4e7369209340",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                 Ingredient\n",
       "0                        TJ’s Salted Butter\n",
       "1                         TJ’s Fresh Garlic\n",
       "2                         TJ’s Fresh Ginger\n",
       "3                 TJ’s Jasmine Rice, rinsed\n",
       "4                                     water\n",
       "...                                     ...\n",
       "2590      TJ's Blueberries, fresh or frozen\n",
       "2591    TJ's Organic Basil, cut into strips\n",
       "2592              TJ's Ciliegine Mozzarella\n",
       "2593              TJ's Balsamic Vinaigrette\n",
       "2594  TJ's ground Black Pepper, or to taste\n",
       "\n",
       "[2595 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ingredient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TJ’s Salted Butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TJ’s Fresh Garlic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TJ’s Fresh Ginger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TJ’s Jasmine Rice, rinsed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>TJ's Blueberries, fresh or frozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>TJ's Organic Basil, cut into strips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>TJ's Ciliegine Mozzarella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>TJ's Balsamic Vinaigrette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>TJ's ground Black Pepper, or to taste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2595 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:34:31.331079Z",
     "start_time": "2025-10-29T16:34:31.279079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create SQLite DB in project folder\n",
    "engine = create_engine(\"sqlite:///cookbook.db\")\n",
    "\n",
    "# Unique ingredient and quantity lookup tables\n",
    "ingredient_df = cookbook_df[[\"ingredient_name\"]].drop_duplicates().reset_index(drop=True)\n",
    "ingredient_df[\"ingredient_id\"] = ingredient_df.index + 1\n",
    "\n",
    "quantity_df = cookbook_df[[\"quantity_text\"]].drop_duplicates().reset_index(drop=True)\n",
    "quantity_df[\"quantity_id\"] = quantity_df.index + 1\n",
    "\n",
    "# Recipe table\n",
    "recipe_df = recipes[[\"title\", \"category\", \"url\", \"image_url\", \"serves\", \"time\"]].drop_duplicates().reset_index(drop=True)\n",
    "recipe_df[\"recipe_id\"] = recipe_df.index + 100  # just an example offset\n",
    "\n",
    "# Link table (Cookbook)\n",
    "cookbook_link = (\n",
    "    cookbook_df.merge(ingredient_df, on=\"ingredient_name\")\n",
    "               .merge(quantity_df, on=\"quantity_text\")\n",
    "               .merge(recipe_df, on=\"title\")\n",
    "               [[\"recipe_id\", \"ingredient_id\", \"quantity_id\"]]\n",
    ")\n",
    "\n",
    "# Write to SQLite\n",
    "ingredient_df.to_sql(\"ingredient\", engine, if_exists=\"replace\", index=False)\n",
    "quantity_df.to_sql(\"quantity\", engine, if_exists=\"replace\", index=False)\n",
    "recipe_df.to_sql(\"recipe\", engine, if_exists=\"replace\", index=False)\n",
    "cookbook_link.to_sql(\"recipe_ingredient\", engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"✅ Cookbook database built successfully.\")"
   ],
   "id": "54824e025a7877a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cookbook database built successfully.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:34:59.312782Z",
     "start_time": "2025-10-29T16:34:59.271866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Option A: seed from a quick Python list (edit to your real pantry) ---\n",
    "pantry_names = [\n",
    "    \"TJ’s Salted Butter\",\n",
    "    \"TJ’s Fresh Garlic\",\n",
    "    \"TJ’s Jasmine Rice\",\n",
    "    \"TJ’s Sea Salt\",\n",
    "    \"TJ’s Large Eggs\",\n",
    "    \"water\",\n",
    "    \"TJ’s Zucchini, sliced into thin planks\",\n",
    "    \"TJ’s Crunchy Sesame Sunflower Seeds Pepitas Salsa Macha\",\n",
    "    \"TJ’s Authentic Greek Feta In Brine, crumbled\",\n",
    "    \"TJ’s Lemon\",\n",
    "    \"TJ’s Cauliflower, sliced into thick planks, core intact\",\n",
    "    \"TJ’s Hot Honey Mustard Dressing\",\n",
    "    \"TJ’s Heirloom Tomatoes, sliced into thick rounds\",\n",
    "    \"TJ’s Organic Ranch Dressing\",\n",
    "    \"TJ’s Olive Oil\",\n",
    "    \"TJ’s Angus Chuck, Brisket, & Sirloin 1/3 lb. Ground Beef Patties\",\n",
    "    \"TJ’s Triple Cream Soft Ripened Cambozola® Blue Cheese, sliced into rectangles\",\n",
    "    \"TJ’s Brioche Buns\",\n",
    "    \"TJ’s Fig Butter\",\n",
    "    \"TJ’s Arugula\",\n",
    "    \"TJ’s Zucchini, stems removed and sliced lengthwise into thin planks\"\n",
    "]\n",
    "\n",
    "# --- Option B: or load from a CSV with a single column 'ingredient_name' ---\n",
    "# pantry_names = pd.read_csv(\"my_pantry.csv\")[\"ingredient_name\"].tolist()\n",
    "\n",
    "# Map names -> ingredient_id using the existing ingredient table\n",
    "ingredient = pd.read_sql(\"SELECT ingredient_id, ingredient_name FROM ingredient\", engine)\n",
    "pantry_df = (\n",
    "    pd.DataFrame({\"ingredient_name\": pantry_names})\n",
    "    .merge(ingredient, on=\"ingredient_name\", how=\"inner\")\n",
    "    [[\"ingredient_id\"]]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Optional: add free-text notes (e.g., amounts you actually have)\n",
    "pantry_df[\"on_hand_note\"] = None\n",
    "\n",
    "# Write/replace the pantry table\n",
    "pantry_df.to_sql(\"pantry\", engine, if_exists=\"replace\", index=False)\n",
    "\n",
    "print(\"✅ Pantry table created with\", len(pantry_df), \"items\")"
   ],
   "id": "106a5b0ba6e285bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pantry table created with 20 items\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:35:01.362861Z",
     "start_time": "2025-10-29T16:35:01.346797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    "  r.recipe_id,\n",
    "  r.title,\n",
    "  1.0 * COUNT(p.ingredient_id) / COUNT(DISTINCT ri.ingredient_id) AS coverage\n",
    "FROM recipe r\n",
    "JOIN recipe_ingredient ri ON ri.recipe_id = r.recipe_id\n",
    "LEFT JOIN pantry p ON p.ingredient_id = ri.ingredient_id\n",
    "GROUP BY r.recipe_id, r.title\n",
    "ORDER BY coverage DESC, r.title;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(sql, engine)\n",
    "df_top_ten = df.head(10)\n",
    "print(df_top_ten)"
   ],
   "id": "921bd1b58189dc18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   recipe_id                                title  coverage\n",
      "0        109  Grilled & Glazed Cauliflower Steaks  1.000000\n",
      "1        108    Grilled Zucchini with Salsa Macha  1.000000\n",
      "2        121            Fig & Blue Cheese Burgers  0.875000\n",
      "3        110               Fried Ranch-y Tomatoes  0.500000\n",
      "4        100          Aromatic Garlic Ginger Rice  0.428571\n",
      "5        309          Gnocchi with Ricotta & Peas  0.375000\n",
      "6        122             Zucchini & Ricotta Rolls  0.375000\n",
      "7        483     Cranberry Pistachio Cheese Balls  0.333333\n",
      "8        237       Maple Marshmallow Popcorn Bars  0.333333\n",
      "9        576            Oat Beverage Matcha Latte  0.333333\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:35:28.521821Z",
     "start_time": "2025-10-29T16:35:28.487961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sql_per_recipe = \"\"\"\n",
    "WITH coverage AS (\n",
    "  SELECT r.recipe_id, r.title,\n",
    "         1.0 * SUM(CASE WHEN p.ingredient_id IS NOT NULL THEN 1 ELSE 0 END)\n",
    "           / COUNT(DISTINCT ri.ingredient_id) AS coverage\n",
    "  FROM recipe r\n",
    "  JOIN recipe_ingredient ri ON ri.recipe_id = r.recipe_id\n",
    "  LEFT JOIN pantry p ON p.ingredient_id = ri.ingredient_id\n",
    "  GROUP BY r.recipe_id, r.title\n",
    "),\n",
    "top10 AS (\n",
    "  SELECT recipe_id, title, coverage\n",
    "  FROM coverage\n",
    "  ORDER BY coverage DESC, title\n",
    "  LIMIT 10\n",
    "),\n",
    "missing AS (\n",
    "  SELECT t.recipe_id, t.title, i.ingredient_name, q.quantity_text\n",
    "  FROM top10 t\n",
    "  JOIN recipe_ingredient ri ON ri.recipe_id = t.recipe_id\n",
    "  JOIN ingredient i ON i.ingredient_id = ri.ingredient_id\n",
    "  JOIN quantity   q ON q.quantity_id   = ri.quantity_id\n",
    "  LEFT JOIN pantry p ON p.ingredient_id = ri.ingredient_id\n",
    "  WHERE p.ingredient_id IS NULL\n",
    ")\n",
    "SELECT\n",
    "  ingredient_name,\n",
    "  REPLACE(GROUP_CONCAT(DISTINCT quantity_text), ',', ' | ') AS suggested_amounts,\n",
    "  COUNT(DISTINCT recipe_id)                                   AS recipes_needing\n",
    "FROM missing\n",
    "GROUP BY ingredient_name\n",
    "ORDER BY recipes_needing DESC, ingredient_name;\n",
    "\"\"\"\n",
    "\n",
    "sql_consolidated = \"\"\"\n",
    "WITH coverage AS (\n",
    "  SELECT r.recipe_id, r.title,\n",
    "         1.0 * SUM(CASE WHEN p.ingredient_id IS NOT NULL THEN 1 ELSE 0 END)\n",
    "           / COUNT(DISTINCT ri.ingredient_id) AS coverage\n",
    "  FROM recipe r\n",
    "  JOIN recipe_ingredient ri ON ri.recipe_id = r.recipe_id\n",
    "  LEFT JOIN pantry p ON p.ingredient_id = ri.ingredient_id\n",
    "  GROUP BY r.recipe_id, r.title\n",
    "),\n",
    "top10 AS (\n",
    "  SELECT recipe_id, title, coverage\n",
    "  FROM coverage\n",
    "  ORDER BY coverage DESC, title\n",
    "  LIMIT 10\n",
    "),\n",
    "missing AS (\n",
    "  SELECT t.recipe_id, t.title, i.ingredient_name, q.quantity_text\n",
    "  FROM top10 t\n",
    "  JOIN recipe_ingredient ri ON ri.recipe_id = t.recipe_id\n",
    "  JOIN ingredient i ON i.ingredient_id = ri.ingredient_id\n",
    "  JOIN quantity   q ON q.quantity_id   = ri.quantity_id\n",
    "  LEFT JOIN pantry p ON p.ingredient_id = ri.ingredient_id\n",
    "  WHERE p.ingredient_id IS NULL\n",
    "),\n",
    "-- do DISTINCT here, not inside GROUP_CONCAT\n",
    "dedup_qty AS (\n",
    "  SELECT ingredient_name, quantity_text\n",
    "  FROM missing\n",
    "  GROUP BY ingredient_name, quantity_text\n",
    "),\n",
    "need_counts AS (\n",
    "  SELECT ingredient_name, COUNT(DISTINCT recipe_id) AS recipes_needing\n",
    "  FROM missing\n",
    "  GROUP BY ingredient_name\n",
    ")\n",
    "SELECT d.ingredient_name,\n",
    "       GROUP_CONCAT(d.quantity_text, ' | ') AS suggested_amounts,\n",
    "       n.recipes_needing\n",
    "FROM dedup_qty d\n",
    "JOIN need_counts n USING (ingredient_name)\n",
    "GROUP BY d.ingredient_name\n",
    "ORDER BY n.recipes_needing DESC, d.ingredient_name;\n",
    "\"\"\"\n",
    "\n",
    "missing_per_recipe = pd.read_sql(sql_per_recipe, engine)\n",
    "grocery_list = pd.read_sql(sql_consolidated, engine)\n",
    "\n",
    "print(\"Missing per recipe (top 10):\")\n",
    "# print(missing_per_recipe.head(20))\n",
    "# print(\"\\nConsolidated grocery list:\")\n",
    "print(grocery_list)"
   ],
   "id": "f1f5e5fc2404ed71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing per recipe (top 10):\n",
      "                                      ingredient_name  \\\n",
      "0   (24.3 ounces) TJ’s Caro Sugo Italian Tomato Ba...   \n",
      "1   (six ounce) bag TJ’s Mini Maple Flavored Marsh...   \n",
      "2         TJ's Matcha Green Tea Single-Serve Packages   \n",
      "3                         TJ's Non-Dairy Oat Beverage   \n",
      "4                                TJ’s 100% Canola Oil   \n",
      "5                              TJ’s Black Peppercorns   \n",
      "6              TJ’s Chicken Broth Concentrate packets   \n",
      "7                    TJ’s Cranberry Chevre (seasonal)   \n",
      "8                                   TJ’s Cream Cheese   \n",
      "9           TJ’s Dried Cranberries, very finely diced   \n",
      "10  TJ’s Dry Roasted & Salted Pistachio Nutmeats, ...   \n",
      "11                                  TJ’s English Peas   \n",
      "12                                   TJ’s Fresh Basil   \n",
      "13                      TJ’s Fresh Basil, for garnish   \n",
      "14                                  TJ’s Fresh Ginger   \n",
      "15                                       TJ’s Gnocchi   \n",
      "16  TJ’s Grated Pecorino Romano & Parmesan Cheese ...   \n",
      "17          TJ’s Green Onion, thinly sliced on a bias   \n",
      "18              TJ’s Japanese Style Panko Breadcrumbs   \n",
      "19                          TJ’s Jasmine Rice, rinsed   \n",
      "20                         TJ’s Movie Theater Popcorn   \n",
      "21                    TJ’s Organic Crushed Red Pepper   \n",
      "22                             TJ’s Part Skim Ricotta   \n",
      "23                      TJ’s Red Onion, thinly sliced   \n",
      "24                  TJ’s Sea Salt, plus more to taste   \n",
      "25                    TJ’s Shredded Mozzarella Cheese   \n",
      "26                            TJ’s Whole Milk Ricotta   \n",
      "\n",
      "              suggested_amounts  recipes_needing  \n",
      "0                         1 jar                1  \n",
      "1                             1                1  \n",
      "2                     1 package                1  \n",
      "3                       3/4 cup                1  \n",
      "4                          None                1  \n",
      "5                          None                1  \n",
      "6                             2                1  \n",
      "7                         1 log                1  \n",
      "8                     1 package                1  \n",
      "9                       1/4 cup                1  \n",
      "10                      3/4 cup                1  \n",
      "11                    ½ package                1  \n",
      "12                ½ cup chopped                1  \n",
      "13                         None                1  \n",
      "14  1 tablespoon finely chopped                1  \n",
      "15                    1 package                1  \n",
      "16                        ½ cup                1  \n",
      "17                            1                1  \n",
      "18                   1 - 2 cups                1  \n",
      "19                        1 cup                1  \n",
      "20                       8 cups                1  \n",
      "21                   1 teaspoon                1  \n",
      "22                        1 tub                1  \n",
      "23                            1                1  \n",
      "24            Add 2 tablespoons                1  \n",
      "25                         None                1  \n",
      "26                      1/3 cup                1  \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T16:35:42.315046Z",
     "start_time": "2025-10-29T16:35:42.261176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# meal_plan_min_waste.py\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "DB_URL = \"sqlite:///cookbook.db\"   # adjust if needed\n",
    "\n",
    "# ---------- SQL building blocks (SQLite-safe; no DISTINCT in 2-arg group_concat) ----------\n",
    "\n",
    "SQL_MISSING_TOP10 = \"\"\"\n",
    "WITH coverage AS (\n",
    "  SELECT r.recipe_id, r.title,\n",
    "         1.0 * SUM(CASE WHEN p.ingredient_id IS NOT NULL THEN 1 ELSE 0 END)\n",
    "           / COUNT(DISTINCT ri.ingredient_id) AS coverage\n",
    "  FROM recipe r\n",
    "  JOIN recipe_ingredient ri ON ri.recipe_id = r.recipe_id\n",
    "  LEFT JOIN pantry p ON p.ingredient_id = ri.ingredient_id\n",
    "  GROUP BY r.recipe_id, r.title\n",
    "),\n",
    "top10 AS (\n",
    "  SELECT recipe_id, title, coverage\n",
    "  FROM coverage\n",
    "  ORDER BY coverage DESC, title\n",
    "  LIMIT 10\n",
    ")\n",
    "SELECT\n",
    "  t.recipe_id,\n",
    "  t.title,\n",
    "  i.ingredient_name,\n",
    "  q.quantity_text\n",
    "FROM top10 t\n",
    "JOIN recipe_ingredient ri ON ri.recipe_id = t.recipe_id\n",
    "JOIN ingredient i         ON i.ingredient_id = ri.ingredient_id\n",
    "JOIN quantity   q         ON q.quantity_id   = ri.quantity_id\n",
    "LEFT JOIN pantry p        ON p.ingredient_id = ri.ingredient_id\n",
    "WHERE p.ingredient_id IS NULL\n",
    "ORDER BY t.title, i.ingredient_name;\n",
    "\"\"\"\n",
    "\n",
    "def load_top10_missing(engine) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns one row per missing ingredient for each of the Top-10 coverage recipes.\n",
    "    Columns: recipe_id, title, ingredient_name, quantity_text\n",
    "    \"\"\"\n",
    "    return pd.read_sql(SQL_MISSING_TOP10, engine)\n",
    "\n",
    "\n",
    "# ---------- Planning utilities ----------\n",
    "\n",
    "def rank_recipes_by_shared_missing(missing_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds summary metrics per recipe using only the Top-10 set:\n",
    "      - total_missing: count of missing ingredients for the recipe\n",
    "      - shared_missing: how many of those are used by >= 2 of the Top-10 recipes\n",
    "      - share_shared_missing: shared_missing / total_missing\n",
    "    \"\"\"\n",
    "    # how many recipes (within top-10) need each ingredient\n",
    "    need_counts = (\n",
    "        missing_df.groupby(\"ingredient_name\")[\"recipe_id\"]\n",
    "        .nunique()\n",
    "        .rename(\"recipes_needing\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    # join back to tag each (recipe, ingredient) as shared (>=2) or not\n",
    "    tag = missing_df.merge(need_counts, on=\"ingredient_name\", how=\"left\")\n",
    "    tag[\"is_shared\"] = (tag[\"recipes_needing\"] >= 2).astype(int)\n",
    "\n",
    "    # per-recipe metrics\n",
    "    per_recipe = (\n",
    "        tag.groupby([\"recipe_id\", \"title\"])\n",
    "           .agg(total_missing=(\"ingredient_name\", \"nunique\"),\n",
    "                shared_missing=(\"is_shared\", \"sum\"))\n",
    "           .reset_index()\n",
    "    )\n",
    "    per_recipe[\"share_shared_missing\"] = (\n",
    "        per_recipe[\"shared_missing\"] / per_recipe[\"total_missing\"].where(per_recipe[\"total_missing\"] > 0, 1)\n",
    "    )\n",
    "    # high to low: prioritize recipes that share more of their missing items\n",
    "    per_recipe = per_recipe.sort_values(\n",
    "        by=[\"share_shared_missing\", \"shared_missing\", \"title\"],\n",
    "        ascending=[False, False, True]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return per_recipe\n",
    "\n",
    "\n",
    "def greedy_select_recipes(missing_df: pd.DataFrame, k: int = 4) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Greedy heuristic to pick k recipes that minimize new unique ingredients introduced.\n",
    "    Start from the best 'share_shared_missing' recipe, then iteratively add the recipe\n",
    "    that adds the fewest new ingredients to the current selection.\n",
    "    Returns a DataFrame of the selected recipes with the ranking metrics attached.\n",
    "    \"\"\"\n",
    "    metrics = rank_recipes_by_shared_missing(missing_df)\n",
    "    # map recipe -> its missing ingredient set\n",
    "    recipe_sets = (\n",
    "        missing_df.groupby([\"recipe_id\", \"title\"])[\"ingredient_name\"]\n",
    "        .apply(lambda s: set(s.unique()))\n",
    "        .reset_index(name=\"missing_set\")\n",
    "    )\n",
    "\n",
    "    selected_rows = []\n",
    "    selected_ings: set[str] = set()\n",
    "\n",
    "    # seed with the best-ranked recipe\n",
    "    seed = metrics.iloc[0]\n",
    "    selected_ids = {int(seed[\"recipe_id\"])}\n",
    "    selected_rows.append(seed)\n",
    "    selected_ings |= recipe_sets.loc[\n",
    "        (recipe_sets[\"recipe_id\"] == seed[\"recipe_id\"]), \"missing_set\"\n",
    "    ].iloc[0]\n",
    "\n",
    "    # iteratively pick the recipe that adds the fewest new ingredients\n",
    "    while len(selected_ids) < min(k, metrics.shape[0]):\n",
    "        best_row = None\n",
    "        best_score = None\n",
    "\n",
    "        for _, row in metrics.iterrows():\n",
    "            rid = int(row[\"recipe_id\"])\n",
    "            if rid in selected_ids:\n",
    "                continue\n",
    "            ing_set = recipe_sets.loc[recipe_sets[\"recipe_id\"] == rid, \"missing_set\"].iloc[0]\n",
    "            new_ings = ing_set - selected_ings\n",
    "            overlap = len(ing_set & selected_ings)\n",
    "\n",
    "            # score: minimize new ingredients, break ties by larger overlap and better share_shared_missing\n",
    "            score_tuple = (len(new_ings), -overlap, -row[\"share_shared_missing\"], row[\"title\"])\n",
    "\n",
    "            if (best_score is None) or (score_tuple < best_score):\n",
    "                best_score = score_tuple\n",
    "                best_row = row\n",
    "\n",
    "        selected_rows.append(best_row)\n",
    "        selected_ids.add(int(best_row[\"recipe_id\"]))\n",
    "        selected_ings |= recipe_sets.loc[\n",
    "            (recipe_sets[\"recipe_id\"] == best_row[\"recipe_id\"]), \"missing_set\"\n",
    "        ].iloc[0]\n",
    "\n",
    "    return pd.DataFrame(selected_rows).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def per_recipe_missing_for_selection(missing_df: pd.DataFrame, selected_ids: list[int]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter 'missing_df' down to the chosen recipes and return\n",
    "    (recipe_id, title, ingredient_name, quantity_text), sorted nicely.\n",
    "    \"\"\"\n",
    "    sel = (\n",
    "        missing_df[missing_df[\"recipe_id\"].isin(selected_ids)]\n",
    "        .copy()\n",
    "        .sort_values(by=[\"title\", \"ingredient_name\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return sel\n",
    "\n",
    "\n",
    "def consolidated_grocery_list(missing_df: pd.DataFrame, selected_ids: list[int],\n",
    "                              require_multi_use: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a master grocery list from the chosen recipes.\n",
    "    - If require_multi_use=True, keep only ingredients used by >=2 of the chosen recipes.\n",
    "    - Quantities are shown as a pipe-joined list of distinct texts (no SQLite DISTINCT bug here).\n",
    "    Returns: ingredient_name | suggested_amounts | recipes_needing\n",
    "    \"\"\"\n",
    "    sel = missing_df[missing_df[\"recipe_id\"].isin(selected_ids)].copy()\n",
    "\n",
    "    # count, within the selection, how many recipes need each ingredient\n",
    "    need_counts_sel = (\n",
    "        sel.groupby(\"ingredient_name\")[\"recipe_id\"]\n",
    "           .nunique()\n",
    "           .rename(\"recipes_needing\")\n",
    "           .reset_index()\n",
    "    )\n",
    "    if require_multi_use:\n",
    "        keep = need_counts_sel[\"recipes_needing\"] >= 2\n",
    "        need_counts_sel = need_counts_sel[keep]\n",
    "\n",
    "    # distinct quantities per ingredient within the selection\n",
    "    qty_map = (\n",
    "        sel.groupby([\"ingredient_name\"])[\"quantity_text\"]\n",
    "           .apply(lambda s: \" | \".join(sorted(set([q for q in s.dropna().astype(str) if q.strip()]))))\n",
    "           .rename(\"suggested_amounts\")\n",
    "           .reset_index()\n",
    "    )\n",
    "\n",
    "    out = need_counts_sel.merge(qty_map, on=\"ingredient_name\", how=\"left\")[\n",
    "        [\"ingredient_name\", \"suggested_amounts\", \"recipes_needing\"]\n",
    "    ].sort_values(by=[\"recipes_needing\", \"ingredient_name\"], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---------- Example end-to-end run ----------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    engine = create_engine(DB_URL)\n",
    "\n",
    "    # 1) Pull Top-10 by coverage (missing items only)\n",
    "    missing_top10 = load_top10_missing(engine)\n",
    "    if missing_top10.empty:\n",
    "        raise SystemExit(\"No missing ingredients found. Did you seed your pantry and recipe tables?\")\n",
    "\n",
    "    # 2) See which recipes are best for overlap (minimize waste)\n",
    "    ranked = rank_recipes_by_shared_missing(missing_top10)\n",
    "    # print(\"\\nTop-10 recipes ranked by shared-missing ratio:\")\n",
    "    # print(ranked[[\"recipe_id\", \"title\", \"shared_missing\", \"total_missing\", \"share_shared_missing\"]].head(10))\n",
    "\n",
    "    # 3) Greedy pick N recipes (change k= to your weekly plan size)\n",
    "    selected = greedy_select_recipes(missing_top10, k=4)\n",
    "    selected_ids = selected[\"recipe_id\"].astype(int).tolist()\n",
    "    # print(\"\\nSelected recipes (greedy, k=4):\")\n",
    "    # print(selected[[\"recipe_id\", \"title\", \"shared_missing\", \"total_missing\", \"share_shared_missing\"]])\n",
    "\n",
    "    # 4a) Per-recipe missing checklist for the chosen set\n",
    "    per_recipe = per_recipe_missing_for_selection(missing_top10, selected_ids)\n",
    "    # print(\"\\nPer-recipe missing items (chosen set):\")\n",
    "    # print(per_recipe.head(20))\n",
    "\n",
    "    # 4b) Consolidated grocery list, only multi-use items (>=2 recipes)\n",
    "    grocery_multi = consolidated_grocery_list(missing_top10, selected_ids, require_multi_use=True)\n",
    "    print(\"\\nConsolidated grocery list (multi-use only):\")\n",
    "    print(grocery_multi)\n",
    "\n",
    "    # 4c) (Optional) If you want EVERYTHING needed (even single-use), set require_multi_use=False\n",
    "    grocery_all = consolidated_grocery_list(missing_top10, selected_ids, require_multi_use=False)\n",
    "    # print(\"\\nConsolidated grocery list (all missing items):\")\n",
    "    # print(grocery_all)\n",
    "\n",
    "    # (Optional) Save to CSVs for printing/sharing\n",
    "    # per_recipe.to_csv(\"per_recipe_missing_selected.csv\", index=False)\n",
    "    # grocery_multi.to_csv(\"grocery_multi_use_selected.csv\", index=False)\n",
    "    # grocery_all.to_csv(\"grocery_all_selected.csv\", index=False)"
   ],
   "id": "8a128dbb49d8939b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consolidated grocery list (multi-use only):\n",
      "Empty DataFrame\n",
      "Columns: [ingredient_name, suggested_amounts, recipes_needing]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4b91038bb28e5dfd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
